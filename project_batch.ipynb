{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import json\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import math\n",
    "import h5py\n",
    "from enum import Enum\n",
    "\n",
    "use_cuda = 1#torch.cuda.is_available()\n",
    "use_pca = 1\n",
    "separate_train_videos_to_activity_regions = 1\n",
    "separate_val_videos_to_activity_regions = 1\n",
    "monotonic_loss_param = 60\n",
    "val_id_num = 100\n",
    "train_id_num = 1000 #len(train_ids)\n",
    "n_epochs_for_second_training_phase = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(i, l):\n",
    "    a = np.zeros(l, 'uint8')\n",
    "    a[i] = 1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = json.load(open('data/activity_net.v1-3.min.json'))\n",
    "features_file = h5py.File('data/sub_activitynet_v1-3.c3d.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(list(data['database'].keys()))\n",
    "video_id_to_idx = {entry:i for i,entry in enumerate(list(data['database'].keys()))}\n",
    "video_idx_to_id = {i:entry for i,entry in enumerate(list(data['database'].keys()))}\n",
    "video_ids = list(data['database'].keys())\n",
    "train_ids = []\n",
    "test_ids = []\n",
    "val_ids = []\n",
    "for video_id in video_ids:\n",
    "    if (data['database'][video_id]['subset'] == 'validation'):\n",
    "        val_ids.append(video_id)\n",
    "    if (data['database'][video_id]['subset'] == 'training'):\n",
    "        train_ids.append(video_id)\n",
    "    if (data['database'][video_id]['subset'] == 'testing'):\n",
    "        test_ids.append(video_id)    \n",
    "labels = set()        \n",
    "for video_id in train_ids:\n",
    "    labels.add(data['database'][video_id]['annotations'][0]['label'])\n",
    "label_to_id = {entry:(i+1) for i,entry in enumerate(list(labels))}\n",
    "label_to_id['none'] = 0\n",
    "label_num = len(label_to_id)\n",
    "id_to_label = {(i+1):entry for i,entry in enumerate(list(labels))}\n",
    "id_to_label[0] = 'none'\n",
    "#print(label_to_id)\n",
    "#print(len(train_ids), len(test_ids), len(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_id_to_categories = defaultdict(list)\n",
    "train_id_to_features = defaultdict(list)\n",
    "skipped = 0\n",
    "new_train_ids = []\n",
    "max_frame_num = 0\n",
    "remove_ids = []\n",
    "\n",
    "for video_id in train_ids: #2d array of features for each video. dim0 depends on video len. dim2=500\n",
    "    \n",
    "    all_features = features_file['v_' + video_id]['c3d_features']\n",
    "    duration = data['database'][video_id]['duration']\n",
    "    frame_num = features_file['v_' + video_id]['c3d_features'].shape[0]\n",
    "    \n",
    "    if (separate_train_videos_to_activity_regions==1):\n",
    "        video_id_used = 0\n",
    "        for i,item in enumerate(data['database'][video_id]['annotations']):\n",
    "            start_frame_idx = int((item['segment'][0]/duration)*frame_num)\n",
    "            end_frame_idx = min(int((item['segment'][1]/duration)*frame_num), frame_num)\n",
    "            f_frame_num = end_frame_idx - start_frame_idx\n",
    "            if (f_frame_num==0):\n",
    "                break\n",
    "            \n",
    "            if (f_frame_num > max_frame_num):\n",
    "                max_frame_num = f_frame_num\n",
    "                \n",
    "            if (video_id_used==0):\n",
    "                new_video_id = video_id\n",
    "                video_id_used = 1\n",
    "            else: \n",
    "                new_video_id = video_id + '%d' % i;\n",
    "                new_train_ids.append(new_video_id)\n",
    "                \n",
    "            if (start_frame_idx==0):\n",
    "                train_id_to_features[new_video_id] = all_features[start_frame_idx:end_frame_idx, :]\n",
    "                train_id_to_categories[new_video_id] = np.full(f_frame_num, label_to_id[item['label']]) \n",
    "            else:                \n",
    "                train_id_to_features[new_video_id] = all_features[start_frame_idx-1:end_frame_idx, :]        \n",
    "                train_id_to_categories[new_video_id] = np.full(f_frame_num+1, label_to_id[item['label']]) \n",
    "                train_id_to_categories[new_video_id][0] = label_to_id['none']\n",
    "                \n",
    "    else:\n",
    "        \n",
    "        train_id_to_features[video_id] = all_features       \n",
    "        train_id_to_categories[video_id] = [label_to_id['none']] * frame_num\n",
    "        #print(video_id, frame_num)\n",
    "        for item in data['database'][video_id]['annotations']:\n",
    "            start_frame_idx = ((item['segment'][0]/duration)*frame_num)\n",
    "            end_frame_idx = ((item['segment'][1]/duration)*frame_num)\n",
    "            #print(item['label'], start_frame_idx, end_frame_idx)\n",
    "            for frame in range(int(start_frame_idx), min(frame_num, int(end_frame_idx))):\n",
    "                #y = one_hot(label_to_id[item['label']], label_num)\n",
    "                y = label_to_id[item['label']]\n",
    "                train_id_to_categories[video_id][frame] = y\n",
    "                \n",
    "train_ids = train_ids + new_train_ids\n",
    "#train_ids = set(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_ids = []\n",
    "for video_id in train_ids:\n",
    "    if (len(train_id_to_categories[video_id])==0):\n",
    "        remove_ids.append(video_id)\n",
    "\n",
    "for id in remove_ids:\n",
    "    train_ids.remove(id)\n",
    "\n",
    "print(len(remove_ids), len(train_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(train_id_to_features['6uhLrPgbpUA']), train_id_to_features['6uhLrPgbpUA'][2].shape)\n",
    "#print(skipped)\n",
    "\n",
    "print(remove_ids)\n",
    "print(train_id_to_features['BrnUW2LSJDI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_id_to_categories = defaultdict(list)\n",
    "val_id_to_features = defaultdict(list)\n",
    "val_id_to_activity_regions = defaultdict(list)\n",
    "skipped = 0\n",
    "new_val_ids = []\n",
    "remove_ids = []\n",
    "for video_id in val_ids: #2d array of features for each video. dim0 depends on video len. dim2=500\n",
    "    \n",
    "    all_features = features_file['v_' + video_id]['c3d_features']\n",
    "    duration = data['database'][video_id]['duration']\n",
    "    frame_num = features_file['v_' + video_id]['c3d_features'].shape[0]\n",
    "    if (separate_val_videos_to_activity_regions==1):\n",
    "        video_id_used = 0\n",
    "        for i,item in enumerate(data['database'][video_id]['annotations']):\n",
    "            \n",
    "            start_frame_idx = int((item['segment'][0]/duration)*frame_num)\n",
    "            end_frame_idx = min(int((item['segment'][1]/duration)*frame_num), frame_num)\n",
    "            f_frame_num = end_frame_idx - start_frame_idx\n",
    "            \n",
    "            if (f_frame_num<4):\n",
    "                break\n",
    "                \n",
    "            if (video_id_used==0):\n",
    "                new_video_id = video_id\n",
    "                video_id_used = 1\n",
    "            else: \n",
    "                new_video_id = video_id + '%d' % i;\n",
    "                new_val_ids.append(new_video_id)    \n",
    "                \n",
    "            if (start_frame_idx==0):\n",
    "                val_id_to_features[new_video_id] = all_features[start_frame_idx:end_frame_idx, :]\n",
    "                val_id_to_categories[new_video_id] = np.full(f_frame_num, label_to_id[item['label']]) \n",
    "            else:                \n",
    "                val_id_to_features[new_video_id] = all_features[start_frame_idx-1:end_frame_idx, :]        \n",
    "                val_id_to_categories[new_video_id] = np.full(f_frame_num+1, label_to_id[item['label']]) \n",
    "                val_id_to_categories[new_video_id][0] = label_to_id['none']\n",
    "        \n",
    "               \n",
    "    else:\n",
    "        \n",
    "        val_id_to_features[video_id] = all_features\n",
    "        val_id_to_categories[video_id] = [label_to_id['none']] * frame_num\n",
    "        #print(video_id, frame_num)\n",
    "        for item in data['database'][video_id]['annotations']:\n",
    "            start_frame_idx = ((item['segment'][0]/duration)*frame_num)\n",
    "            end_frame_idx = ((item['segment'][1]/duration)*frame_num)\n",
    "            val_id_to_activity_regions[video_id].append([int(start_frame_idx), min(frame_num, int(end_frame_idx))])\n",
    "            #print(item['label'], start_frame_idx, end_frame_idx)\n",
    "            for frame in range(int(start_frame_idx), min(frame_num, int(end_frame_idx))):\n",
    "                val_id_to_categories[video_id][frame] = label_to_id[item['label']]\n",
    "                \n",
    "val_ids = val_ids + new_val_ids\n",
    "val_ids = list(set(val_ids))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_ids = []\n",
    "for video_id in val_ids:\n",
    "    if (len(val_id_to_categories[video_id])==0):\n",
    "        remove_ids.append(video_id)\n",
    "\n",
    "for id in remove_ids:\n",
    "    val_ids.remove(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs - train_id_to_features\n",
    "#print(len(train_id_to_features), train_id_to_features['sJFgo9H6zNo'].shape)\n",
    "#outputs - train_id_to_categories\n",
    "#print(len(train_id_to_categories), len(train_id_to_categories['sJFgo9H6zNo']), train_id_to_categories['sJFgo9H6zNo'][0].shape)\n",
    "\n",
    "#print(train_id_to_features['sJFgo9H6zNo'][0,:].squeeze().shape)\n",
    "#print(train_id_to_categories['sJFgo9H6zNo'][0].squeeze().shape)\n",
    "print(len(remove_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Detector(nn.Module):\n",
    "    def __init__(self, hidden_size, input_size, output_size, use_soft_max):\n",
    "        super(Detector, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.use_soft_max = use_soft_max\n",
    "        if (use_soft_max):\n",
    "            self.softmax = nn.Softmax(output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output, hidden = self.lstm(input, hidden)\n",
    "        output = self.linear(output)\n",
    "        if (self.use_soft_max):\n",
    "            output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(1, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 500 if use_pca else 4096\n",
    "hidden_size = 500 if use_pca else 512\n",
    "output_size = label_num\n",
    "learning_rate = 0.01 #consider starting from 0.01 and divide by 10 every N iterations\n",
    "back_prop_depth = 1000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "softmax = nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ResetModel():\n",
    "    detector = Detector(hidden_size, input_size, output_size, 0).cuda() if use_cuda else Detector(hidden_size, input_size, output_size, 0)\n",
    "    detector_optimizer = torch.optim.Adam(detector.parameters(), learning_rate)\n",
    "    return detector, detector_optimizer\n",
    "\n",
    "decoder, decoder_optimizier = ResetModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossFuncType(Enum):\n",
    "    CE = 1\n",
    "    EARLY = 2   \n",
    "    MONOTONIC = 3\n",
    "    EARLY_MONOTONIC = 4\n",
    "    MIXED = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvertDictTo2DArray(d):\n",
    "    lend = len(d.keys())\n",
    "    keys = np.fromiter(d.keys(), dtype=float)\n",
    "    vals = np.fromiter(d.values(), dtype=float)\n",
    "    keys.shape = (lend, 1)\n",
    "    vals.shape = (lend, 1)\n",
    "    return tuple(map(tuple, np.append(keys, vals, axis=1).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CrossEntropyLossFunc(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLossFunc, self).__init__()\n",
    "        \n",
    "    def forward(self,detector_output, target_variable, target_variable_one_hot):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = 0\n",
    "        loss_arr_scalar = []\n",
    "        for di in range(target_variable.shape[0]):\n",
    "            curr_target = target_variable[di] #1x201\n",
    "            #curr_target = curr_target.cuda() if use_cuda else curr_target         \n",
    "            loss_step = criterion(detector_output[di], curr_target)\n",
    "            loss += loss_step\n",
    "            loss_arr_scalar.append(loss_step.cpu().data[0])\n",
    "                \n",
    "        return loss, loss_arr_scalar\n",
    "    \n",
    "class EarlyLossFunc(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(EarlyLossFunc,self).__init__()\n",
    "        \n",
    "    def forward(self,detector_output, target_variable, target_variable_one_hot):\n",
    "        loss = 0\n",
    "        T = target_variable.shape[0]\n",
    "        N = label_num\n",
    "        B = target_variable.shape[1]\n",
    "        #print(B)\n",
    "        loss_arr_scalar = []\n",
    "        detector_output_after_softmax = softmax(detector_output)\n",
    "        detector_output_after_softmax_one_hot = detector_output_after_softmax * target_variable_one_hot\n",
    "        detector_output_after_softmax_one_hot_inverse = 1 - detector_output_after_softmax * target_variable_one_hot\n",
    "\n",
    "        for di in range(T): #di=0..T-1\n",
    "\n",
    "            false_neg = (-((di+1)/(T+1)) * detector_output_after_softmax_one_hot_inverse[di, :, :] * \n",
    "                                torch.log1p(-detector_output_after_softmax[di, :, :]))\n",
    "\n",
    "            false_pos = (-detector_output_after_softmax_one_hot[di, :, :] * \n",
    "                         torch.log(detector_output_after_softmax[di, :, :]))\n",
    " \n",
    "            loss_step = (false_neg.sum() + false_pos.sum())\n",
    "            \n",
    "            loss += loss_step\n",
    "            loss_arr_scalar.append(loss_step.cpu().data[0])\n",
    "    \n",
    "        return loss, loss_arr_scalar\n",
    "\n",
    "    \n",
    "class MonotonicLossFunc(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, param):\n",
    "        super(MonotonicLossFunc, self).__init__()\n",
    "        self.param = param\n",
    "        \n",
    "    def forward(self,detector_output, target_variable, target_variable_one_hot):\n",
    "        loss = 0\n",
    "        T = target_variable.shape[0]\n",
    "        N = label_num\n",
    "        B = target_variable.shape[1]\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss_arr_scalar = []\n",
    "        detector_output_after_softmax = softmax(detector_output)\n",
    "        detector_output_after_softmax_one_hot = detector_output_after_softmax * target_variable_one_hot\n",
    "        \n",
    "        for di in range(T): #di=0..T-1\n",
    "     \n",
    "            if (di==0):\n",
    "                loss_r = 0\n",
    "            else:\n",
    "                current_activity_list = detector_output_after_softmax_one_hot[0:di, :, :]\n",
    "                max_last_score, indices = torch.max(current_activity_list, dim=0)\n",
    "                #print(\"max_score: \", max_last_score.data, \"curr score: \", detector_output_after_softmax_one_hot[di, :, :].data)\n",
    "                loss_r_matrix = torch.clamp(max_last_score - detector_output_after_softmax_one_hot[di, :, :], min=0)\n",
    "                #print(\"loss matrix: \", loss_r_matrix, loss_r_matrix.sum())\n",
    "                loss_r = loss_r_matrix.sum()/B       \n",
    "            \n",
    "            loss_c = criterion(detector_output[di], target_variable[di])  \n",
    "            if (di>0):\n",
    "                print(loss_c.data[0], loss_r.data[0])\n",
    "            else:\n",
    "                print(loss_c.data[0], loss_r)\n",
    "                \n",
    "            loss_step = loss_c + self.param * loss_r\n",
    "            loss += loss_step\n",
    "            loss_arr_scalar.append(loss_step.cpu().data[0])\n",
    "            \n",
    "        \n",
    "        return loss, loss_arr_scalar\n",
    "    \n",
    "class EarlyMonotonicLossFunc(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, param):\n",
    "        super(EarlyMonotonicLossFunc, self).__init__()\n",
    "        self.param = param\n",
    "        \n",
    "    def forward(self,detector_output, target_variable, target_variable_one_hot):\n",
    "        loss = 0\n",
    "        T = target_variable.shape[0]\n",
    "        N = label_num\n",
    "        B = target_variable.shape[1]\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss_arr_scalar = []\n",
    "        detector_output_after_softmax = softmax(detector_output)\n",
    "        detector_output_after_softmax_one_hot = detector_output_after_softmax * target_variable_one_hot\n",
    "        \n",
    "        for di in range(T): #di=0..T-1\n",
    "     \n",
    "            if (di==0):\n",
    "                loss_r = 0\n",
    "            else:\n",
    "                current_activity_list = detector_output_after_softmax_one_hot[0:di, :, :]\n",
    "                max_last_score, indices = torch.max(current_activity_list, dim=0)\n",
    "                loss_r_matrix = torch.clamp(max_last_score - detector_output_after_softmax_one_hot[di, :, :], min=0)\n",
    "                loss_r = loss_r_matrix.sum()/B       \n",
    "            \n",
    "            loss_c = criterion(detector_output[di], target_variable[di])            \n",
    "            loss_step = ((di+1)/(T+1)) * ( loss_c + self.param * loss_r )\n",
    "            loss += loss_step\n",
    "            loss_arr_scalar.append(loss_step.cpu().data[0])\n",
    "        \n",
    "        return loss, loss_arr_scalar   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iteration(target_variable, target_variable_one_hot, input_variable, \n",
    "          model, \n",
    "          optimizer, \n",
    "          loss_func, frame_num): \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    target_length = frame_num #len(target_variable)\n",
    "    batch_size = target_variable.shape[1]\n",
    "    #print(batch_size, target_variable.shape)\n",
    "    loss_arr_per_frame = []\n",
    "    detector_hidden = detector.initHidden(batch_size)\n",
    "    detector_hidden = detector_hidden.cuda() if use_cuda else detector_hidden\n",
    "    detector_cells = detector.initHidden(batch_size)\n",
    "    detector_cells = detector_cells.cuda() if use_cuda else detector_cells\n",
    "    \n",
    "    detector_output = []\n",
    "    detector_output = Variable(torch.zeros(target_length, batch_size, label_num))\n",
    "    detector_output = detector_output.cuda() if use_cuda else detector_output\n",
    "    #print(len(target_variable))\n",
    "    \n",
    "    score_per_frame = []\n",
    "    \n",
    "    for di in range(target_length):\n",
    "        #input len 500\n",
    "        detector_input = np.array(input_variable[di, :, :]) #1x500\n",
    "        detector_input = Variable(torch.FloatTensor(detector_input)).view(1,batch_size,-1)\n",
    "        detector_input = detector_input.cuda() if use_cuda else detector_input\n",
    "        #print(detector_input.shape, detector_hidden.shape)\n",
    "        detector_output_single, (detector_hidden, detector_cells) = model(detector_input, (detector_hidden, detector_cells))\n",
    "        detector_output[di] = detector_output_single\n",
    "        #topv, topi= softmax(detector_output_single).data.topk(1)\n",
    "        #ind_pos = target_variable[di].astype(int).tolist()\n",
    "        #print((detector_output_single).shape, (detector_input).shape)\n",
    "        curr_cat = target_variable[di, 0].cpu().data[0];\n",
    "        topv, topi = softmax(detector_output_single[0, :, :].squeeze()).data.topk(1)\n",
    "        #print(\"top score = \", topv[0])\n",
    "        #score_per_frame.append(softmax(detector_output_single[0, 0, :])[curr_cat].data[0])\n",
    "        #print(topv.shape)\n",
    "        score_per_frame.append(topv.sum()/batch_size)\n",
    "     \n",
    "    loss, loss_arr_scalar = loss_func(detector_output, target_variable, target_variable_one_hot)    \n",
    "    if (back_prop_depth > target_length):\n",
    "        loss.backward()\n",
    "        #print(loss)\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    return loss.cpu().data[0], score_per_frame, loss_arr_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "def FindLongestVideoLenInABatch(ids):\n",
    "    result = 0\n",
    "    for id in ids:\n",
    "        if (len(train_id_to_categories[id]) == 0):\n",
    "            print(\"ERROR: FindLongestVideoLenInABatch id= \", id)\n",
    "        if (train_id_to_categories[id].shape[0] > result):\n",
    "            \n",
    "            result = train_id_to_categories[id].shape[0]\n",
    "    return result\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n",
    "    lr = learning_rate * (0.1 ** (epoch // 5))\n",
    "    print(\"set lr to \", lr, \" on epoch \", epoch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(nepochs, batch_size, train_id_num, model, optimizer, loss_func, loss_type, second_loss_func = EarlyLossFunc()):\n",
    "    loss_arr_per_frame = []\n",
    "    loss_progress = []\n",
    "    iter_print_freq = 20\n",
    "    nbatches = train_id_num/batch_size\n",
    "    print(\"Staring training. nepochs=\", nepochs, \" nbatches=\", nbatches, \" batch_size=\", batch_size)\n",
    "    for iter in range(nepochs):\n",
    "        adjust_learning_rate(optimizer, iter)\n",
    "        for bid in range(int(nbatches)):\n",
    "            max_frame_num = FindLongestVideoLenInABatch(train_ids[bid*batch_size : (bid+1)*batch_size])\n",
    "            #print(\"Longest video len = \", max_frame_num)\n",
    "            target_variable = np.zeros((max_frame_num, batch_size), dtype=int)\n",
    "            target_variable_one_hot = np.zeros((max_frame_num, batch_size, label_num), dtype=int)\n",
    "            input_variable = np.zeros((max_frame_num, batch_size, input_size))\n",
    "            \n",
    "            for i,train_id in enumerate(train_ids[bid*batch_size : (bid+1)*batch_size]):\n",
    "                curr_frame_num = train_id_to_categories[train_id].shape[0]\n",
    "                target_variable[0:curr_frame_num, i] = train_id_to_categories[train_id]\n",
    "                target_variable_one_hot[0:curr_frame_num, i, :] = one_hot(train_id_to_categories[train_id], label_num)\n",
    "                input_variable[0:curr_frame_num, i, :] = train_id_to_features[train_id];\n",
    "               \n",
    "            if (loss_type == LossFuncType.MIXED and (iter>=(nepochs-n_epochs_for_second_training_phase))):\n",
    "                loss_func = second_loss_func\n",
    "                #print(\"Starting second training phase for MIXED loss function\")\n",
    "            \n",
    "            target_variable = Variable(torch.LongTensor(target_variable))\n",
    "            target_variable = target_variable.cuda() if use_cuda else target_variable\n",
    "            \n",
    "            target_variable_one_hot = Variable(torch.FloatTensor(target_variable_one_hot))\n",
    "            target_variable_one_hot = target_variable_one_hot.cuda() if use_cuda else target_variable_one_hot\n",
    "            \n",
    "            loss, score_per_frame, loss_arr_scalar = train_iteration(target_variable, target_variable_one_hot, input_variable, model, optimizer, loss_func, max_frame_num)\n",
    "            np.resize(score_per_frame, (1, train_id_to_categories[train_ids[bid*batch_size]].shape[0]))\n",
    "            curr_average_loss = loss/max_frame_num;\n",
    "            if ((bid % iter_print_freq) == 0):\n",
    "                loss_progress.append(curr_average_loss)\n",
    "                print(\"epoch: \", iter, \"batch: \", bid, \"loss: \", curr_average_loss)\n",
    "                \n",
    "            if (bid >= train_id_num):\n",
    "                break\n",
    "          \n",
    "    return loss_arr_scalar, score_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetLossFunc(loss_type):\n",
    "    if (loss_type == LossFuncType.CE):\n",
    "        return CrossEntropyLossFunc()\n",
    "    if (loss_type == LossFuncType.EARLY):\n",
    "        return EarlyLossFunc()\n",
    "    if (loss_type == LossFuncType.MONOTONIC):\n",
    "        return MonotonicLossFunc(monotonic_loss_param)\n",
    "    if (loss_type == LossFuncType.EARLY_MONOTONIC):\n",
    "        return EarlyMonotonicLossFunc(monotonic_loss_param) \n",
    "    if (loss_type == LossFuncType.MIXED):\n",
    "        return CrossEntropyLossFunc()\n",
    "    \n",
    "def GetSecondMixedLossFunc():\n",
    "    return EarlyMonotonicLossFunc(monotonic_loss_param) \n",
    "\n",
    "def GetModelName(loss_type):\n",
    "    if (loss_type == LossFuncType.CE):\n",
    "        return 'detector_ce.pt'\n",
    "    if (loss_type == LossFuncType.EARLY):\n",
    "        return 'detector_early.pt'\n",
    "    if (loss_type == LossFuncType.MONOTONIC):\n",
    "        return 'detector_monotonic.pt'\n",
    "    if (loss_type == LossFuncType.EARLY_MONOTONIC):\n",
    "        return 'detector_early_monotonic.pt'\n",
    "    if (loss_type == LossFuncType.MIXED):\n",
    "        return 'detector_mixed.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nepochs = 20\n",
    "batch_size = 64\n",
    "train_id_num = 6400\n",
    "learning_rate = 0.01\n",
    "#loss_types = [LossFuncType.CE, LossFuncType.MONOTONIC, LossFuncType.EARLY, LossFuncType.EARLY_MONOTONIC, LossFuncType.MIXED]\n",
    "loss_types = [LossFuncType.CE, LossFuncType.MONOTONIC, LossFuncType.EARLY_MONOTONIC]\n",
    "loss_arrs_per_frame = []\n",
    "scores_per_frame = []\n",
    "models = []\n",
    "for loss_type in loss_types:\n",
    "    loss_func = GetLossFunc(loss_type)\n",
    "    detector, detector_optimizer = ResetModel()\n",
    "    loss_arr_per_frame, score_per_frame = train(nepochs, batch_size, train_id_num, detector, detector_optimizer, loss_func, loss_type, second_loss_func = GetSecondMixedLossFunc())\n",
    "    loss_arrs_per_frame.append(loss_arr_per_frame)\n",
    "    scores_per_frame.append(score_per_frame)\n",
    "    model_name = GetModelName(loss_type)    \n",
    "    torch.save(detector, model_name)\n",
    "    models.append(detector.cpu())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('scores_per_frame.npy', scores_per_frame)\n",
    "np.save('loss_arrs_per_frame.npy', loss_arrs_per_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_per_frame = np.load('scores_per_frame.npy')\n",
    "loss_arrs_per_frame = np.load('loss_arrs_per_frame.npy')\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('scores per frame')\n",
    "for i,loss_type in enumerate(loss_types):\n",
    "    plt.plot(scores_per_frame[i][0:40], label=GetModelName(loss_type))\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title('loss_arrs_per_frame')\n",
    "for i,loss_type in enumerate(loss_types):\n",
    "    plt.plot(loss_arrs_per_frame[i][0:40], label=GetModelName(loss_type))\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference_iteration(detector, input_variable):\n",
    "    detector_hidden = detector.initHidden(1)\n",
    "    detector_hidden = detector_hidden.cuda() if use_cuda else detector_hidden\n",
    "    \n",
    "    detector_cells = detector.initHidden(1)\n",
    "    detector_cells = detector_cells.cuda() if use_cuda else detector_cells\n",
    "    \n",
    "    input_len = input_variable.shape[0]\n",
    "    categories_per_frame = []\n",
    "    scores_per_frame = []\n",
    "    \n",
    "    for di in range(input_len):\n",
    "        #input len 500\n",
    "        detector_input = np.array(input_variable[di,:]) #1x500\n",
    "        detector_input = Variable(torch.FloatTensor(detector_input)).view(1,1,-1)\n",
    "        detector_input = detector_input.cuda() if use_cuda else detector_input\n",
    "        #\n",
    "        detector_output, (detector_hidden, detector_cells) = detector(detector_input, (detector_hidden, detector_cells))\n",
    "        #topv, topi= softmax(detector_output).data.topk(5)\n",
    "        \n",
    "        topv, topi = softmax(detector_output[0, 0, :]).data.topk(1)\n",
    "        #print(\"top score = \", topv[0])\n",
    "        #score_per_frame.append(topv[0])\n",
    "        ni = topi[0] #category id\n",
    "        nv = topv[0] #score\n",
    "        categories_per_frame.append(ni)\n",
    "        scores_per_frame.append(nv)\n",
    "            \n",
    "    return np.array(categories_per_frame), np.array(scores_per_frame) #nframesx1 each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(model_name, val_id_num):\n",
    "    print(\"inference called with model_name: \", model_name)\n",
    "    all_categories = []\n",
    "    all_scores = []\n",
    "    all_categories_true = []\n",
    "    model = torch.load(model_name)\n",
    "    model.lstm.flatten_parameters()\n",
    "    max_val_video_len = 0\n",
    "    binary_success = []\n",
    "    for i,val_id in enumerate(val_ids):\n",
    "        input_variable = val_id_to_features[val_id];\n",
    "        categories, scores = inference_iteration(model, input_variable)\n",
    "        if (max_val_video_len < input_variable.shape[0]):\n",
    "            max_val_video_len = input_variable.shape[0]\n",
    "        all_categories.append(categories)\n",
    "        all_scores.append(scores)\n",
    "        all_categories_true.append(val_id_to_categories[val_id])\n",
    "        binary_success.append((categories == np.array(val_id_to_categories[val_id])).astype(int))\n",
    "        if (i >= val_id_num):\n",
    "            break\n",
    "\n",
    "    return binary_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CropAndPad(input_res, crop_frame):\n",
    "    for i in range(len(input_res)):\n",
    "        #remove the first one, since its non activity\n",
    "        #input_res[i] = input_res[i][1:input_res[i].shape[0]];\n",
    "    \n",
    "        if (input_res[i].shape[0] > crop_frame):\n",
    "            input_res[i] = input_res[i][0:crop_frame]\n",
    "        else:\n",
    "            pad_size = crop_frame - input_res[i].shape[0]\n",
    "            input_res[i] = np.pad(input_res[i], (0, pad_size), 'edge')\n",
    "        if (input_res[i].shape[0] != crop_frame):\n",
    "            print(input_res[i].shape[0])\n",
    "        \n",
    "    return input_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_types = [LossFuncType.MONOTONIC]\n",
    "loss_types = [LossFuncType.CE, LossFuncType.MONOTONIC, LossFuncType.EARLY_MONOTONIC]\n",
    "average_accuracy_per_frame = []\n",
    "val_id_num = 100\n",
    "for i,loss_type in enumerate(loss_types):\n",
    "    binary_classify_success = inference(GetModelName(loss_type), val_id_num)\n",
    "    binary_classify_success = CropAndPad(binary_classify_success, crop_frame=20)\n",
    "    average_accuracy_per_frame.append(sum(binary_classify_success)/len(binary_classify_success))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(3)\n",
    "plt.title('average_accuracy_per_frame')\n",
    "for i,loss_type in enumerate(loss_types):\n",
    "    plt.plot(average_accuracy_per_frame[i], label=GetModelName(loss_type))\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
